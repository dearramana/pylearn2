!obj:pylearn2.train.Train {
  dataset: !obj:pylearn2.sandbox.nlp.datasets.word2vec.Word2Vec {
    which_set: 'train',
    stop: None,
  },
  model: !obj:pylearn2.models.mlp.MLP {
    input_space: !obj:pylearn2.sandbox.rnn.space.SequenceSpace {
      space: !obj:pylearn2.space.IndexSpace {
        dim: 1,
        max_labels: 101,
      },
    },
    layers: [
      !obj:pylearn2.sandbox.nlp.models.mlp.ProjectionLayer {
        layer_name: 'projection_layer',
        dim: 500,
        irange: 0.01,
      },
      !obj:pylearn2.sandbox.rnn.models.mlp.RecursiveConvolutionalLayer {
        layer_name: 'rconv_layer',
        dim: 500,
        irange: 0.01,
        activation: 'rect'
      },
      !obj:pylearn2.models.mlp.Linear {
        layer_name: 'linear_layer',
        dim: 300,
        irange: 0.01,
        use_cosine_loss: True
      }
    ],
  },
  algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
    learning_rate: .000001,
    learning_rule: !obj:pylearn2.training_algorithms.learning_rule.AdaDelta {},
    batch_size: 32,
    monitoring_dataset: {
      valid: !obj:pylearn2.sandbox.nlp.datasets.word2vec.Word2Vec {
        which_set: 'valid',
        stop: None
      },
      train: !obj:pylearn2.sandbox.nlp.datasets.word2vec.Word2Vec {
        which_set: 'train',
        stop: 1000 
      },
    },
  },
  save_path: '/data/lisa/exp/kimtaeho/char_embedding/rc_char_embeddings.pkl',
  save_freq: 1,
}
